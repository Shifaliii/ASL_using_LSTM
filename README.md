
# âœ¨ ASL Sign Language Recognition using LSTM, MediaPipe & OpenCV

This project uses deep learning to recognize American Sign Language (ASL) alphabet gestures from real-time webcam feed. It leverages **MediaPipe** for hand tracking, **OpenCV** for capturing images, and a **Keras LSTM model** to learn gesture sequences.



## ğŸ“Œ Features

- ğŸ–ï¸ Real-time hand gesture recognition using webcam
- ğŸ§  Deep learning model (LSTM) trained on 25 static ASL letters (Aâ€“Z excluding J)
- ğŸ’¡ Feedback overlay showing predicted letter and confidence
- ğŸ“ Easy-to-use scripts for data collection, keypoint extraction, model training, and deployment



## ğŸ–¼ï¸ Project Structure

```plaintext
SignLanguageDetectionUsingML/
â”œâ”€â”€ Image/                  # Raw gesture images captured via webcam
â”œâ”€â”€ MP_Data/               # Extracted MediaPipe keypoints (.npy files)
â”œâ”€â”€ Logs/                  # TensorBoard logs
â”œâ”€â”€ model.h5               # Trained LSTM model weights
â”œâ”€â”€ model.json             # Model architecture (optional)
â”œâ”€â”€ app.py                 # Real-time sign detection and prediction
â”œâ”€â”€ collectiondata.py      # Image collection script
â”œâ”€â”€ data.py                # Keypoint extraction from images
â”œâ”€â”€ train_model.py         # LSTM model training
â”œâ”€â”€ modelsummary.py        # To view model structure
â”œâ”€â”€ function.py            # Shared utility functions (MediaPipe logic)
â”œâ”€â”€ requirements.txt       # Required Python packages
â””â”€â”€ README.md              # You're here!
```



## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/Shifaliii/ASL_using_LSTM.git
cd ASL_using_LSTM
```

### 2. Create a virtual environment (optional but recommended)

```bash
python -m venv venv
venv\Scripts\activate  # On Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```



## ğŸ“· Data Collection

Run the script below to collect images for each alphabet gesture using your webcam:

```bash
python collectiondata.py
```

- Press keys like `a`, `b`, `c`, ... to save corresponding gesture images.
- Images are saved in `Image/A/`, `Image/B/`, etc.



## ğŸ” Extract Keypoints

Convert images to hand landmark keypoints using MediaPipe:

```bash
python data.py
```

- Saves 21 keypoints per frame as `.npy` files inside `MP_Data/`.



## ğŸ‹ï¸â€â™€ï¸ Train the LSTM Model

Train an LSTM model on the extracted sequences:

```bash
python train_model.py
```

- Trains a 3-layer LSTM with dense layers
- Saves model as `model.h5` and `model.json`
- Logs progress to `Logs/` for TensorBoard



## ğŸ§  Model Architecture

```python
model = Sequential()
model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,63)))
model.add(LSTM(128, return_sequences=True, activation='relu'))
model.add(LSTM(64, return_sequences=False, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(25, activation='softmax'))  # 25 signs (J excluded)
```



## ğŸ“ˆ Training Results

- âœ… Accuracy after 200 epochs: ~97â€“99%
- ğŸ“‰ Loss steadily decreased across epochs
- ğŸ“‚ You can visualize training with:
  ```bash
  tensorboard --logdir Logs/
  ```



## ğŸ¥ Real-time Prediction

Run the main app to detect ASL gestures live:

```bash
python app.py
```

- Opens webcam and shows prediction + accuracy
- Only works for the 25 trained letters (J excluded)



## ğŸ§ª Troubleshooting

| Problem | Solution |
|--------|----------|
| Webcam not opening | Make sure it's not in use by another app |
| MediaPipe errors | Use Python 3.10 with `mediapipe==0.10.14` |
| Permission error on `venv\Scripts\activate` | Run PowerShell as Admin:<br> `Set-ExecutionPolicy RemoteSigned` |
| Model not detecting well | Collect more diverse images; train longer |



## ğŸ“¦ Requirements

These are available in `requirements.txt`:

```txt
opencv-python==4.12.0.88
mediapipe==0.10.14
tensorflow==2.11.0
keras==2.11.0
numpy==1.23.5
protobuf==3.20.3
```





## ğŸ¤ Contributing

Pull requests are welcome.  
For major changes, please open an issue first to discuss your ideas.



## ğŸ“¬ Contact

**Shifali Florine Lobo**  
[GitHub](https://github.com/Shifaliii)




